{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Econ570 Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: graphviz in c:\\users\\admin\\anaconda3\\lib\\site-packages (0.19.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import graphviz as gr\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "style.use(\"fivethirtyeight\")\n",
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## helper functions\n",
    "\n",
    "def fn_variance(data, ddof=0):\n",
    "    n = len(data)\n",
    "    mean = sum(data) / n\n",
    "    return sum((x - mean) ** 2 for x in data) / (n - ddof)\n",
    "\n",
    "def fn_generate_cov(dim, corr):\n",
    "    acc  = []\n",
    "    for i in range(dim):\n",
    "        row = np.ones((1,dim)) * corr\n",
    "        row[0][i] = 1\n",
    "        acc.append(row)\n",
    "    return np.concatenate(acc,axis=0)\n",
    "\n",
    "def fn_generate_multnorm(nobs,corr,nvar):\n",
    "\n",
    "    mu = np.zeros(nvar)\n",
    "    std = (np.abs(np.random.normal(loc = 1, scale = .5,size = (nvar,1))))**(1/2)\n",
    "    # generate random normal distribution\n",
    "    acc = []\n",
    "    for i in range(nvar):\n",
    "        acc.append(np.reshape(np.random.normal(mu[i],std[i],nobs),(nobs,-1)))\n",
    "    \n",
    "    normvars = np.concatenate(acc,axis=1)\n",
    "\n",
    "    cov = fn_generate_cov(nvar, corr)\n",
    "    C = np.linalg.cholesky(cov)\n",
    "\n",
    "    Y = np.transpose(np.dot(C,np.transpose(normvars)))\n",
    "\n",
    "#     return (Y,np.round(np.corrcoef(Y,rowvar=False),2))\n",
    "    return Y\n",
    "\n",
    "def fn_randomize_treatment(N,p=0.5):\n",
    "    treated = random.sample(range(N), round(N*p))\n",
    "    return np.array([(1 if i in treated else 0) for i in range(N)]).reshape([N,1])\n",
    "\n",
    "def fn_bias_rmse_size(theta0,thetahat,se_thetahat,cval = 1.96):\n",
    "    \"\"\"\n",
    "    theta0 - true parameter value\n",
    "    thetatahat - estimated parameter value\n",
    "    se_thetahat - estiamted se of thetahat\n",
    "    \"\"\"\n",
    "    b = thetahat - theta0\n",
    "    bias = np.mean(b)\n",
    "    rmse = np.sqrt(np.mean(b**2))\n",
    "    tval = b/se_thetahat # paramhat/se_paramhat H0: theta = 0\n",
    "    size = np.mean(1*(np.abs(tval)>cval))\n",
    "    # note size calculated at true parameter value\n",
    "    return (bias,rmse,size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q1\n",
    "$y_i = \\tau*T_i+\\beta'*x_i+e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to simulate data y\n",
    "def fn_generate_y(T,X,C,tau,N,p,corr,conf = True,conx = True,contf = True,contx = True):\n",
    "    \"\"\"\n",
    "    T: treatment effect\n",
    "    X: observed covariates\n",
    "    C: confounders\n",
    "    tau: treatment effect parameter\n",
    "    N: sample size\n",
    "    p: number of covariates\n",
    "    corr: correlation for multivariate normal\n",
    "    conf: indicating the existence of confounding factors\n",
    "    conx: indicating the existence of covariates factors\n",
    "    contx: indicating whether we control the covariates\n",
    "    contf: indicating whether we control the confoundings\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    corr = 0.5 \n",
    "\n",
    "    if conf == False:\n",
    "        conf_mult = 0 # remove confounder from outcome\n",
    "    else:\n",
    "        conf_mult = 1\n",
    "\n",
    "    if conx == False:\n",
    "        conx_mult = 0 # remove observed covariates from outcome\n",
    "    else:\n",
    "        conx_mult = 1\n",
    "\n",
    "\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    beta0 = np.random.normal(5,5,[p,1]) #the matrix of true parameters of the observed covariates\n",
    "\n",
    "    Yab = tau*T+conx_mult*X@beta0+conf_mult*0.6*C+err\n",
    "    \n",
    "    if contf == False:\n",
    "        C = np.zeros([N,1]) \n",
    "        \n",
    "    if contx == False:\n",
    "        X = np.zeros([N,1])\n",
    "\n",
    "    \n",
    "    if conf == True:\n",
    "        return (Yab, T, C)\n",
    "\n",
    "    if conx == True:\n",
    "        return (Yab, T, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to simulate data y,T,x\n",
    "def fn_generate_data(tau,N,p,corr,conf = True,conx = True,contf = True,contx = True):\n",
    "    \n",
    "    nvar = p+1 # 1 confounder and variable for randomizing treatment\n",
    "    \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    C = allX[:,0].reshape([N,1])\n",
    "    \n",
    "    X = allX[:,1:] \n",
    "    T = fn_randomize_treatment(N)\n",
    "    \n",
    "    Y, T, X = fn_generate_y(T,X,C,tau,N,p,corr,conf,conx,contf,contx)\n",
    "    \n",
    "    return Y, T, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a DGP\n",
    "\n",
    "tau = 2\n",
    "N = 100\n",
    "p = 1\n",
    "\n",
    "Y, T, X = fn_generate_data(tau,N,p, corr = 0.5,conf = False,conx = True,contf = False,contx = True)\n",
    "\n",
    "\n",
    "matrix = np.hstack([Y,T,X])\n",
    "data_Q1 = pd.DataFrame(matrix, columns=['Y', 'T', 'X'])\n",
    "data_Q1.to_csv(\"data_Q1.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"134pt\" height=\"116pt\"\n",
       " viewBox=\"0.00 0.00 134.00 116.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 112)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-112 130,-112 130,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"63\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"63\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M35.35,-72.76C39.71,-64.28 45.15,-53.71 50.04,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"53.23,-45.64 54.7,-35.15 47.01,-42.44 53.23,-45.64\"/>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"99\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"99\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.65,-72.76C86.29,-64.28 80.85,-53.71 75.96,-44.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"78.99,-42.44 71.3,-35.15 72.77,-45.64 78.99,-42.44\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x187474379a0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustrate DGP with a DAG\n",
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"Y\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to estimate the treatment effect of random sample using OLS\n",
    "def fn_estimate_params(Y,T,X):\n",
    "    \"\"\"\n",
    "    Y: Outcome value of Dependent Variable\n",
    "    T: Indicating the treatment group 0/1\n",
    "    X: Value of observed covariates/Value of Confounders\n",
    "    \"\"\"\n",
    "\n",
    "    mod = sm.OLS(Y,T,X)\n",
    "    res = mod.fit()\n",
    "    tauhat = res.params[0]\n",
    "    se_tauhat = res.HC1_se[0]\n",
    "\n",
    "    return tauhat,se_tauhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to do the monte carlo simulation\n",
    "def run_mc_simulation(R,tau,N,p,corr,conf = False,conx = False,contf = True,contx = True):\n",
    "    \"\"\"\n",
    "    R: number of MC replications\n",
    "    tau: treatment effect parameter\n",
    "    N: sample size\n",
    "    p: number of covariates\n",
    "    corr: Correlation for multivariate normal\n",
    "    conf: Indicating the existence of confounding factors\n",
    "    conx: Indicating the existence of covariates factors\n",
    "    contx: Indicating whether we control the covariates\n",
    "    contf: Indicating whether we control the confoundings\n",
    "    \"\"\"\n",
    "\n",
    "    estDict = {}\n",
    "    for n in N:\n",
    "        tauhats = []\n",
    "        sehats = []\n",
    "        for r in tqdm(range(R)):\n",
    "            Y,T,X = fn_generate_data(tau,n,p,corr,conf,conx,contf,contx)\n",
    "            tauhat,sehat = fn_estimate_params(Y,T,X)\n",
    "            tauhats = tauhats + [tauhat]\n",
    "            sehats = sehats + [sehat]\n",
    "        estDict[n] = {\n",
    "        'tauhat':np.array(tauhats).reshape([len(tauhats),1]),\n",
    "        'sehat':np.array(sehats).reshape([len(sehats),1])\n",
    "        }\n",
    "\n",
    "    return estDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to summarize the results of monte carlo simulation\n",
    "def summarize_mc_simulation(tau,R,N,estDict):\n",
    "    tau0 = tau*np.ones([R,1])\n",
    "    for N, results in estDict.items():\n",
    "        (bias,rmse,size) = fn_bias_rmse_size(tau0,results['tauhat'],\n",
    "                                             results['sehat'])\n",
    "\n",
    "        print(f'N={N}: bias={bias}, RMSE={rmse}, size={size}')\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case a : without control for any covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:04<00:00, 468.95it/s]\n",
      "100%|██████████| 2000/2000 [00:34<00:00, 57.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.015907258340033318, RMSE=1.0290427723630646, size=0.0635\n",
      "N=1000: bias=0.0003878033833572725, RMSE=0.3110486793070965, size=0.0505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,corr = 0.5,conf = False,conx = True,contx = False,contf = False)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case b : with control for all the covariates that affect the outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:04<00:00, 460.75it/s]\n",
      "100%|██████████| 2000/2000 [00:21<00:00, 91.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.009545002275571875, RMSE=1.037376451010417, size=0.059\n",
      "N=1000: bias=0.005899208729968047, RMSE=0.3296731739053988, size=0.0515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,corr=0.5,conf = False,conx = True,contf = False,contx = True)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X : The difference between test scores and last semester class average.<br>\n",
    "T : Whether the number of skipped classes in this semester is more than 10 times.<br>\n",
    "Y : The difference between the test scores and the class average.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q2\n",
    "$y_i = \\tau*T_i+\\beta'*x_i+e_i$\n",
    "\n",
    "$T_i=a+b∗x_i+e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to separate the samples to treated and non treated based on confounders\n",
    "def fn_confounders_treatment(C,N):\n",
    "    \"\"\"\n",
    "    C: confounders\n",
    "    N: sample size\n",
    "    \"\"\"\n",
    "\n",
    "    err = np.random.normal(0,1,[N,1])\n",
    "    treated = 1 + 2 * C + err\n",
    "    treated_prob = 1/(1+np.exp(-treated))\n",
    "    \n",
    "    T=np.array([(1 if treated_prob[i] >= 0.5 else 0) for i in range(N)]).reshape([N,1])\n",
    "\n",
    "    return T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to simulate data y,T,x\n",
    "def fn_generate_data(tau,N,p,corr,conf = True,conx = True,contf = True,contx = True):\n",
    "    \n",
    "    nvar = p+1 # 1 confounder\n",
    "    \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    C = allX[:,0].reshape([N,1])\n",
    "    \n",
    "    X = allX[:,1:] \n",
    "    T = fn_confounders_treatment(C,N)\n",
    "    \n",
    "    Y, T, X = fn_generate_y(T,X,C,tau,N,p,corr,conf,conx,contf,contx)\n",
    "    \n",
    "    return Y, T, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate a DGP\n",
    "\n",
    "tau = 2\n",
    "N = 100\n",
    "p = 1\n",
    "\n",
    "Y, T, X = fn_generate_data(tau,N,p,corr = 0.5,conf = True,conx = False,contf = True,contx = False)\n",
    "\n",
    "matrix = np.hstack([Y,T,X])\n",
    "data_Q2 = pd.DataFrame(matrix, columns=['Y', 'T', 'X'])\n",
    "data_Q2.to_csv(\"data_Q2.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- X -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;T -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>X&#45;&gt;T</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1874c22dc40>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustrate DGP with a DAG\n",
    "g = gr.Digraph()\n",
    "g.edge(\"X\", \"T\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case a : without control for the confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 915.47it/s]\n",
      "100%|██████████| 2000/2000 [00:05<00:00, 379.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.2797633839142419, RMSE=0.3272548560741808, size=0.549\n",
      "N=1000: bias=0.28053376142696707, RMSE=0.3041396577949685, size=0.9425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,corr = 0.5,conf = True,conx = False,contf = False,contx = False)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case b : with control for the confounder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 853.67it/s]\n",
      "100%|██████████| 2000/2000 [00:05<00:00, 387.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=0.2754015218224662, RMSE=0.32742354361862164, size=0.5315\n",
      "N=1000: bias=0.2788108930331411, RMSE=0.3021648341841918, size=0.946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,corr = 0.5,conf = True,conx = False,contf = True,contx = False)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X : Average GDP of the region in the past 5 years.<br>\n",
    "T : Whether to implement the subsidy policy.<br>\n",
    "Y : Average salary of the region.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q3\n",
    "$y_i = \\tau*T_i+ \\beta'*x_i + e_i$\n",
    "\n",
    "$x_i = \\alpha*T_i+e_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to simulate selection data\n",
    "def fn_selection_data(T,N,alpha):\n",
    "    \"\"\"\n",
    "    alpha: \n",
    "    \"\"\"\n",
    "    \n",
    "    err1 = np.random.normal(0,1,[N,1])\n",
    "    X = alpha*T + err1\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a function to simulate data y,T,x\n",
    "def fn_generate_data(tau,N,p,corr,conf = True,conx = True,contf = True,contx = True):\n",
    "    \n",
    "    nvar = p+1 # 1 confounder\n",
    "    \n",
    "    allX = fn_generate_multnorm(N,corr,nvar)\n",
    "    C = allX[:,0].reshape([N,1])\n",
    "    \n",
    "    T = fn_randomize_treatment(N)\n",
    "    alpha = 2\n",
    "    X = fn_selection_data(T,N,alpha)\n",
    "    \n",
    "    \n",
    "    Y, T, X = fn_generate_y(T,X,C,tau,N,p,corr,conf,conx,contf,contx)\n",
    "    \n",
    "    return Y, T, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate a DGP\n",
    "tau = 2\n",
    "N = 100\n",
    "p = 1\n",
    "\n",
    "Y, T, X = fn_generate_data(tau,N,p,corr=0.5,conf = False,conx = True,contf = False,contx = True)\n",
    "\n",
    "matrix = np.hstack([Y,T,X])\n",
    "data_Q3 = pd.DataFrame(matrix, columns=['Y', 'T', 'X'])\n",
    "data_Q3.to_csv(\"data_Q3.csv\",index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.46.0 (20210118.1747)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"89pt\" height=\"188pt\"\n",
       " viewBox=\"0.00 0.00 89.00 188.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-184 85,-184 85,4 -4,4\"/>\n",
       "<!-- T -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>T</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-158.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">T</text>\n",
       "</g>\n",
       "<!-- X -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>X</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"27\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-86.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">X</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;X -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>T&#45;&gt;X</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M47.6,-144.41C44.49,-136.34 40.67,-126.43 37.17,-117.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"40.4,-116.03 33.54,-107.96 33.87,-118.55 40.4,-116.03\"/>\n",
       "</g>\n",
       "<!-- Y -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>Y</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"54\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"54\" y=\"-14.3\" font-family=\"Times New Roman,serif\" font-size=\"14.00\">Y</text>\n",
       "</g>\n",
       "<!-- T&#45;&gt;Y -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>T&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.65,-143.91C59.68,-133.57 61.98,-120.09 63,-108 64.34,-92.06 64.34,-87.94 63,-72 62.28,-63.5 60.93,-54.31 59.49,-46.01\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"62.91,-45.29 57.65,-36.09 56.03,-46.56 62.91,-45.29\"/>\n",
       "</g>\n",
       "<!-- X&#45;&gt;Y -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>X&#45;&gt;Y</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M33.4,-72.41C36.51,-64.34 40.33,-54.43 43.83,-45.35\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"47.13,-46.55 47.46,-35.96 40.6,-44.03 47.13,-46.55\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x1874c23fbb0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Illustrate DGP with a DAG\n",
    "g = gr.Digraph()\n",
    "g.edge(\"T\", \"X\")\n",
    "g.edge(\"T\", \"Y\")\n",
    "g.edge(\"X\", \"Y\")\n",
    "g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case a : with control for the variable in between the path from cause to effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 915.30it/s]\n",
      "100%|██████████| 2000/2000 [00:18<00:00, 110.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=10.004771024351054, RMSE=14.197929552751528, size=0.9895\n",
      "N=1000: bias=9.784303134167619, RMSE=13.937558455241644, size=0.996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,corr = 0.5,conf = False,conx = True,contf = False,contx = True)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### case b : without control for the variable in between the path from cause to effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:02<00:00, 821.82it/s]\n",
      "100%|██████████| 2000/2000 [00:18<00:00, 109.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N=100: bias=9.866779127925662, RMSE=14.004831556549044, size=0.988\n",
      "N=1000: bias=10.033161944867116, RMSE=14.148790493324872, size=0.997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_rep = 2000\n",
    "tau = 2\n",
    "N = [100,1000]\n",
    "p = 1\n",
    "\n",
    "estDict = run_mc_simulation(n_rep,tau,N,p,corr = 0.5,conf = False,conx = True,contx = False,contf = False)\n",
    "summarize_mc_simulation(tau,n_rep,N,estDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T : Exercise every day or not.<br>\n",
    "X : Drink more water.<br>\n",
    "Y : Have a healthier body.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
